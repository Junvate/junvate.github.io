# 面试题
## CNN 如何给图像分类（整体流程）
- 输入 (Input):     
    - 一张图像，通常表示为一个像素值的矩阵，RGB三个矩阵。

- 特征提取 (Feature Extraction):
    - 图像通过卷积层，激活函数，池化层
    - 卷积层负责检测图像的边缘，纹理，角点
    - 激活函数引入非线性，学习复杂模式
    - 池化层降低数据空间维度

- 展平 (Flatten)
    - 经过feature exraction之后，会得到 **通道数个** width*heigth的矩阵，会被展平成一个长长的一维向量

- 分类 (Classification)
    - 一维特征被送入全连接层，根据提取到的特征进行分类
- 输出（output）
    - 通过全连接层的输出之后得到多个类别的得分
    - 然后通过一个 softmax() 得到概率向量

## 卷积层是怎么工作的

- 是卷积神经网络的关键，从输入数据之中提取特征
- https://blog.csdn.net/2401_85377976/article/details/141496759
- https://blog.csdn.net/a15608445683/article/details/124541139


## 交叉熵损失 cross entropy loss
- cross entropy loss  是分类问题中常用的损失函数，衡量模型预测的概率分布与真实标签的差异，关注的是真实类别预测的概率
```
$$L = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)$$

$$L = -y_k \log(\hat{y}_k) = -1 \cdot \log(\hat{y}_k) = -\log(\hat{y}_k)$$
```

# 深度神经网络模型
## 卷积神经网络 convolutional neural networks
- 主要用于处理网格状数据


#### LeNet-5
-  最早的成功 CNN 之一，用于手写数字识别。

#### AlexNet
- 在 2012 年 ImageNet 竞赛中取得突破，真正点燃了深度学习在图像领域的应用。

#### ResNet (Residual Network)
- 引入残差连接，解决了极深网络训练困难（梯度消失/爆炸）的问题，是目前应用最广泛的 CNN 架构之一。


## 循环神经网络 recurrent neural networks
- 主要用于处理序列数据，如文本、语音、时间序列

#### Simple RNN
- 基本的 RNN 结构，但存在长期依赖问题（梯度消失/爆炸）。


#### LSTM 
- (Long Short-Term Memory): 通过引入门控机制（输入门、遗忘门、输出门）有效解决了长期依赖问题，是处理序列数据的里程碑模型。

#### GRU 
- (Gated Recurrent Unit): LSTM 的一种简化变体，结构更简单，性能与 LSTM 相当，在某些任务上更受欢迎。


## Transformer模型
- 为自然语言处理设计，基于(Self-Attention)，完全摒弃了 RNN 的循环结构和 CNN 的卷积操作。

#### Transformer 
- (Original): 论文 "Attention Is All You Need" 中提出的基础架构，成为现代 NLP 的基石。

#### BERT 
- (Bidirectional Encoder Representations from Transformers  基于 Transformer 的双向编码器表示): 基于 Transformer 的预训练语言模型，通过双向上下文理解，在多项 NLP 任务中取得 SOTA (State-of-the-art) 效果。


#### GPT 
- (Generative Pre-trained Transformer) 系列 (e.g., GPT-3, GPT-4): 基于 Transformer 的大规模生成式预训练模型，在文本生成、对话等方面能力强大。



## 计算机视觉
计算机视觉是一个广泛的领域，研究如何让计算机从图像或视频中提取信息。多模态则是一种方法，强调结合多种数据模态（如图像、文本、音频）进行分析。在计算机视觉中，多模态研究通常涉及视觉数据与其他模态的交互，例如视觉-语言任务（如图像描述生成或指代表达理解）。因此，多模态可以看作计算机视觉的一个子集或交叉领域，特别是在视觉-语言或视觉-音频任务中。


在计算机视觉中，多模态方法常用于需要结合视觉和其他信息的任务。  
例如：    
指代表达理解（REC）：根据文本描述定位图像中的对象。  
图像描述生成：为图像生成自然语言描述。  
视觉问答（VQA）：根据图像回答文本问题。  

### 视觉定位
视觉定位是指通过图像或视频数据确定物体在三维空间中的位置和姿态（通常包括位置和朝向）。它广泛应用于机器人导航、增强现实（AR）、自动驾驶等领域。

### 图像描述
图像描述是通过算法自动为图像生成自然语言描述，类似于人类对图像内容的总结。它结合了计算机视觉和自然语言处理（NLP）


### 视觉问答
视觉问答是指给定一张图像和一个自然语言问题，模型需要理解图像内容并准确回答问题。这是一个跨模态任务，结合了视觉和语言理解。

### 引用表达式理解 (Referring Expression Comprehension)
引用表达式理解是指根据一段自然语言描述（引用表达式），在图像中定位并识别特定目标物体或区域。例如，给定描述“穿红衣服的人”，模型需在图像中找到对应的对象。

### 图像分割
图像分割是将图像划分为多个有意义的区域或像素组，每个区域对应一个对象或类别。分割任务分为语义分割、实例分割和全景分割。


## OpenCv

OpenCV（Open Source Computer Vision Library）是一个开源的计算机视觉和图像处理库，广泛用于处理图像和视频，支持多种编程语言（如C++、Python、Java），并在实时应用中有优异表现。
```python
import cv2

# 读取图像
img = cv2.imread('image.png')

# 显示图像
cv2.imshow('Image', img)


gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
cv2.imshow('Gray', gray)

blurred = cv2.GaussianBlur(img, (5, 5), 0)
cv2.imshow('Blur', blurred)

edges = cv2.Canny(gray, 100, 200)
cv2.imshow('Edges', edges)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

## Pytroch
### 什么是Pytroch
PyTorch 是一个开源的机器学习框架，由 Facebook（现 Meta AI）开发，广泛用于深度学习研究和生产环境。它以动态计算图（Dynamic Computational Graph）为核心  
PyTorch 支持 Python 和 C++，并在 GPU 上提供高效加速，适用于计算机视觉、自然语言处理、强化学习等领域。

### 基本使用
张量（Tensor）是 PyTorch 的核心数据结构，类似 NumPy 数组。
```
import torch

# 创建张量
x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 2x3 张量
print("Tensor:", x)

# 张量属性
print("Shape:", x.shape)  # 形状
print("Device:", x.device)  # 设备（CPU/GPU）

# 基本运算
y = torch.tensor([[2, 2, 2], [2, 2, 2]])
z = x + y  # 逐元素相加
print("Addition:", z)

# 转换为 GPU（若可用）
if torch.cuda.is_available():
    x = x.to('cuda')
    print("Moved to GPU:", x.device)

# 转换为 NumPy
x_np = x.cpu().numpy()  # 先移回 CPU
print("NumPy array:", x_np)
```
PyTorch 的 autograd 自动计算梯度，用于优化模型参数。
```
import torch

# 创建张量并启用梯度追踪
x = torch.tensor(2.0, requires_grad=True)

# 定义简单函数 y = x^2
y = x ** 2

# 反向传播计算梯度
y.backward()

# 梯度 dy/dx = 2x，在 x=2 时为 4
print("Gradient of x:", x.grad)
```

## Transfomer架构？
https://lwmj4b253w.feishu.cn/docx/R3E3dPJpiohhzUxYxIjcv1GCnKd?from=from_copylink

