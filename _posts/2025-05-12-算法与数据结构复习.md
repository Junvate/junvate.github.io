---
layout:     post
title:      数据结构复习
subtitle:   数据结构复习
date:       2025-05-08
author:     Junvate
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 保研复习
---

# 面试题集
![图片](/img/image-1.png)
## 算法复杂度 (Algorithm Complexity)
- 时间复杂度 (Time Complexity): 估算算法执行所需的时间随输入规模 N 增大的变化趋势。它不是指具体的执行秒数（因为这还依赖于硬件、编程语言等），而是指算法执行的基本操作数量的增长级别。
- 大O符号描述的是算法复杂度的渐进上界 (asymptotic upper bound) 忽略低阶项 忽略常数系数 大O表示法通常描述的是最坏情况下的复杂度，因为它提供了一个性能的保证上限
- O(N) 被称为线性复杂度 (Linear Complexity)。这意味着算法的执行时间（或所需空间）与输入数据的规模 N 成正比关系。
- O(1) - 常数复杂度 (Constant Complexity): 算法的执行时间不随输入规模 N 的变化而变化    
- O(logN) - 对数复杂度 (Logarithmic Complexity): 当 N 增大时，执行时间以对数级别增长
- O(NlogN) - 线性对数复杂度 (Linearithmic Complexity): 常见于高效的排序算法。
例如：归并排序 (Merge Sort)，快速排序 (Quick Sort) 的平均情况，堆排序 (Heap Sort)。
- O(N 2) - 平方复杂度 (Quadratic Complexity): 执行时间与 N 的平方成正比。通常涉及对数据集的嵌套循环。
- O(N!) - 阶乘复杂度 (Factorial Complexity): 执行时间随 N 呈阶乘级增长，比指数级增长更快，非常低效。

## 讲解一下 贪心算法 动态规划算法 和分治法？
- 它在每一步决策时，都采取当前状态下最好或最优的选择，而不从整体最优上加以考虑。它期望通过每一次的局部最优选择，
不一定能得到全局最优解： 贪心算法的致命弱点在于它不能保证最终得到的是全局最优解
- 动态规划算法 （Dynamic Programming,）核心思想是将一个复杂的问题分解为若干个重叠的子问题，记录并复用子问题解，避免重复计算利用已解决的子问题的解来高效地解决更大的问题。 定义状态  找出状态转移方程： 这是动态规划最核心的一步。需要找到当前状态如何由之前的状态推导出来。  确定初始条件（边界条件）  构造最优解
- 分治法的核心思想是将一个难以直接解决的大问题，分割成一些规模较小的子问题，分别解决。然后将各个子问题的解合并起来，从而得到原问题的解。分解 (Divide)： 将原问题分解为若干个规模较小、相互独立、与原问题形式相同的子问题。解决 (Conquer)： 若子问题规模较小且容易解决则直接解决，否则递归地解决各个子问题。合并 (Combine)： 将各个子问题的解合并为原问题的解。


## 哈希函数
- 哈希函数是一种将任意长度的输入数据（也称为“键”或“关键字”，Key）通过一个特定的算法，映射成固定长度的输出（称为“哈希值”、“散列值”或“哈希码”，Hash Code）的函数。
```
hash_value = hash_function(key)
```
-  对于相同的输入键，哈希函数必须总是产生相同的哈希值。这是最基本的要求。 计算哈希值的过程应该非常快，不能成为性能瓶颈。哈希函数应尽可能地将输入键均匀地映射到哈希值空间中的每一个位置。这意味着对于任意一个键，它被映射到任何一个哈希值的概率应该大致相等。这有助于减少哈希冲突。不同的输入键应该尽可能产生不同的哈希值。然而，由于输入空间通常远大于输出空间（哈希值的取值范围有限），哈希冲突（不同的键产生相同的哈希值）是不可避免的。一个好的哈希函数应该努力使冲突的概率降到最低。输入键的微小变化应该导致输出哈希值的巨大且不可预测的变化。这在密码学应用中尤为重要，可以防止通过相似输入来推测原始数据。

- 常见的哈希函数示例：
- 除留余数法 (Division Method)： h(key) = key % M，其中 M 通常是一个质数，作为哈希表的大小。这是最简单也比较常用的一种方法。
- 加密哈希函数： SHA-1, SHA-256, SHA-512 等。这类函数除了上述特性外，还具有单向性（难以从哈希值反推出原始输入）和强抗碰撞性（难以找到两个不同输入产生相同哈希值）。
- 平方取中法 (Mid-square Method)： 计算键的平方，然后取中间的几位作为哈希值。
- 斐波那契散列 (Fibonacci Hashing)
- 字符串哈希函数： 例如 BKDRHash, APHash, DJBHash, SDBMHash, MurmurHash, CityHash, xxHash 等，它们专门为字符串设计，力求在速度和散列均匀性之间取得平衡。


## 哈希表

- 哈希表是一种根据键 (Key) 直接访问内存存储位置的数据结构。










## 各种排序算法
- 一个排序算法是稳定的，如果它能保证在排序完成后，具有相同键值（排序依据的值）的元素保持它们在输入序列中的相对顺序。
各种排序算法的性能总结
不稳定的排序算法有：希尔排序、选择排序、堆排序、快速排序。
--------------------------------------------------
排序方法: 插入排序
时间复杂度 (平均): O(n^2)
时间复杂度 (最坏): O(n^2)
时间复杂度 (最好): O(n)
空间复杂度: O(1)
稳定性: 稳定
--------------------------------------------------
排序方法: 选择排序
时间复杂度 (平均): O(n^2)
时间复杂度 (最坏): O(n^2)
时间复杂度 (最好): O(n^2)
空间复杂度: O(1)
稳定性: 不稳定
这种“交换”操作可能会跨越很长的距离，从而可能改变等值元素的相对顺序。
--------------------------------------------------
排序方法: 快速排序
时间复杂度 (平均): O(n log n)
时间复杂度 (最坏): O(n^2)
时间复杂度 (最好): O(n log n)
空间复杂度: O(log n)
稳定性: 不稳定
选择基准然后分区，把比基准小的放在基准左边，把比基准大的放在基准右边，然后递归，涉及到了交换
--------------------------------------------------
排序方法: 归并排序
时间复杂度 (平均): O(n log n)
时间复杂度 (最坏): O(n log n)
时间复杂度 (最好): O(n log n)
空间复杂度: O(n)
稳定性: 稳定
--------------------------------------------------
★★★★★★归并排序的最坏时间复杂度优于快排，为什么我们还是选择快排？
快速排序通常比归并排序更快。尽管快速排序在最坏情况下的性能可能较差，但在大多数情况下，它的平均时间复杂度要比归并排序低。
快速排序是原地排序算法。原地排序算法是指排序过程中不需要额外的存储空间，只利用原始输入数组进行排序。
快速排序的实现相对简单。相比于归并排序，快速排序的实现更为简洁，代码量更少。
总结：由于快速排序在平均情况下表现更好、占用更少的空间并且更易于实现。
--------------------------------------------------
排序方法: 希尔排序
时间复杂度 (平均): O(n^1.3) (近似值)
时间复杂度 (最坏): O(n^2)
时间复杂度 (最好): O(n)
空间复杂度: O(1)
稳定性: 不稳定
--------------------------------------------------
排序方法: 堆排序
时间复杂度 (平均): O(n log n)
时间复杂度 (最坏): O(n log n)
时间复杂度 (最好): O(n log n)
空间复杂度: O(1)
稳定性: 不稳定
--------------------------------------------------
排序方法: 冒泡排序
时间复杂度 (平均): O(n^2)
时间复杂度 (最坏): O(n^2)
时间复杂度 (最好): O(n)
空间复杂度: O(1)
稳定性: 稳定
--------------------------------------------------






## KMP算法





## 满二叉树和完全二叉树有什么区别？
- 满二叉树高度为h。结点的个数就是2^h-1，除了最后一层叶子结点，所有的结点都有两个孩，每一层都是满的 所有的结点度为2
- 完全二叉树就是在满二叉树的基础上，最后一层从右往左删除一些叶子节点，如果一个结点只有一个叶子结点那一定是左孩子

## 由遍历序列构造二叉树
- 由二叉树的先序序列和中序序列可以唯一地确定一棵二叉树。
- 由二叉树的后序序列和中序序列也可以唯一地确定一棵二叉树。
- 由二叉树的层序序列和中序序列也可以唯一地确定一棵二叉树
- 需要注意的是，若只知道二叉树的先序序列和后序序列，则无法唯一确定一棵二叉树。
- 一定要有中序遍历

## 树的存储结构？


## 二叉搜索树 BST
- 性质；非空左子树的所有键值<根节点键值，非空右子树所有值>根节点键值，左右子树都是二叉搜索树
- 对二叉搜索树进行中序排序会得到排序好的数组，
- 理想情况下的查找速度可以用 O(logn) 来衡量 最差的情况就是非常不平衡退化成链表 于是产生了AVL

## 平衡二叉树 AVL
- 本质是BST，对于树中的任意一个节点，其左子树的深度（高度）与右子树的深度之差的绝对值不能超过1。
- 平衡因子 = 某节点的左子树深度 - 右子树深度，任意结点的平衡因子只能是+1 -1 0
- AVL树在查找操作上能始终保持 O(logn) 的时间复杂度，即使在最坏情况下也是如此。

## 红黑树 RBT
- 根节点和所有叶子结点都是黑色
- 如果一个结点是红色，那他的两个子节点都是黑色，表示不允许出现两个连续的红色结点
- 从任一特定结点到其所有后代叶子结点的路径上黑色结点数量相同


## B树
- 和二叉树不同，可以有多个子节点，B树通常用于数据库和文件系统。
- 什么是B树的阶 ？B树中一个节点的子节点数目的最大值 
- 一棵m阶B树的性质：
    - 每个节点最多只有m个子节点。
    - 每个非叶子节点（除了根）具有至少⌈m/2⌉子节点。
    - 如果根不是叶节点，则根至少有两个子节点。
    - 具有k个子节点的非叶节点包含k -1个键。
    - 所有叶子都出现在同一水平，位于同一层（高度一致）。\


## 什么是哈夫曼树？如何构造？哈夫曼树的应用
- 关键是最小的带权路径长度WPL，哈夫曼树又称为最优二叉树，其特点是，给定一组带权的叶子结点，若构造所得到的二叉树拥有最小的带权路径长度WPL，则称该二叉树为一棵哈夫曼树。

- 构造办法：首先在集合中挑选出两个权值最小的叶子结点进行合并得到新的结点加入集合，再将两个被选中的结点剔除出集合。在树的构造上，将这两个结点作为叶子结点衔接到合并而成的新结点上。重复以上过程直到集合中只有一个元素，哈夫曼树则完成构造。 

- 哈夫曼编码能够保证是前缀码，消除编码的二义性，即每个编码都不是另一个编码的前缀。哈夫曼编码能够保证字符编码总长最短

- 所以，哈夫曼编码的性质有：１，哈夫曼编码是前缀码２，哈夫曼编码是最优前缀码

## 最小生成树？
- 什么是最小生成树 (MST)？在一个连通的、无向的、带权重的图 (Connected, Undirected, Weighted Graph) 中，最小生成树 (MST) 是该图的一个子图，它具备以下特点：包含图中所有的顶点 (Spanning): 子图连接了原图中的每一个顶点。是一棵树 (Tree): 子图是无环的。对于包含 V 个顶点的图，其生成树恰好有 V−1 条边。权重之和最小 (Minimum Weight): 在所有可能的生成树中，该子图的各条边的权重之和是最小的。

- 主要有两种著名的贪心算法可以找到最小生成树：Prim 算法 和 Kruskal 算法。



## 图通常用什么数据结构进行存储？

- 邻接矩阵是用一个二维数组来表示图。如果图有 N 个顶点，那么这个二维数组的大小就是 N×N。对于无权图，如果顶点 i 和顶点 j 之间有边相连，则矩阵中第 i 行第 j 列的元素 A[i][j] 为 1 (或 true)，否则为 0 (或 false)。对于有权图， A[i][j] 表示顶点 i 和顶点 j 之间边的权重。如果两点间没有边，可以表示为无穷大 (Infinity) 或一个特殊值 (如 0，但要注意区分权重为0的情况)。对于无向图，邻接矩阵是对称的，即 A[i][j]=A[j][i]。判断两个顶点之间是否有边非常快，只需要 O(1) 的时间复杂度。空间复杂度较高，为 O(N^2)，其中 N 是顶点数量。对于稀疏图 (边的数量远小于顶点数量的平方) 会浪费大量存储空间。


- 邻接表 (Adjacency List)，邻接表是图的一种链式存储结构。它为图中的每个顶点维护一个列表 (或链表)，这个列表存储了所有与该顶点直接相邻的顶点。通常使用一个数组，数组的每个元素对应图中的一个顶点。数组的每个元素指向一个链表 (或其他动态数据结构，如动态数组、哈希表等)。链表中的每个节点表示与当前顶点相邻的一个顶点。获取一个顶点的所有邻接点非常高效。判断两个顶点之间是否有边，最坏情况下需要遍历其中一个顶点的邻接链表，时间复杂度为 O(degree(v))，其中 degree(v) 是顶点的度。对于稠密图，这个操作可能比邻接矩阵慢。




## 简单介绍dfs和bfs
- dfs是使用栈进行深度优先搜索，按照一个路径一直访问到底，
- bfs是使用队列使用广度优先搜索，先访问源点，然后访问它的相邻结点，根据每个相邻结点的访问，依次继续访问他们的邻居结点
- dfs找到可行解 bfs找到最短路径
