---
layout:     post
title:      线性代数概率论复习
subtitle:   线性代数概率论复习
date:       2025-05-08
author:     Junvate
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 保研复习
---

# 线性代数
## 复习
### 子式

对于一个 m×n 的矩阵 A，一个 k 阶子式是通过以下步骤得到的：
选择 k 行（1≤k≤m）。
选择 k 列（1≤k≤n）。
由这 k 行和 k 列交叉位置上的元素组成一个 k×k 的方阵。
这个 k×k 方阵的**行列式**就称为 A 的一个 k 阶子式。


### 满秩
对于一个 m×n 的矩阵 A，其秩 rank(A) 总是满足：
```
0≤rank(A)≤min(m,n)
rank(A)=m 行满秩 (row full rank)。这意味着矩阵的所有行向量都是线性无关的
rank(A)=n  列满秩 (column full rank)。这意味着矩阵的所有列向量都是线性无关的
对于方阵 (m=n)： 矩阵的秩等于其维度，即 rank(A)=n (或 m)。在这种情况下，我们通常直接称该矩阵为满秩
```

### 线性相关
- 对于一个方阵来说，行列式为 0 是其行向量（或列向量）线性相关的充分必要条件。
- 如果一个矩阵包含一个 k 阶的非零子式，那么对应的 k 行和 k 列是线性无关的 
- 如果这个行列式不为零，这意味着这个 k×k 子矩阵是可逆的。
- 如果矩阵的秩是 r，即存在 r 个线性无关的行向量（或列向量），那么我们可以找到一个 r×r 的子矩阵，其行列式不为零。 


### 基和维数
a. a1,a2,...,ar线性无关;
b. V中向量均可由 a1,a2,..., ar 线性表示
则称 a1,a2,...,ar 为V 的一个基。
基中所含向量个数 r 称为向量空间的维数

### 行列式计算
```
[ a11  a12 ]
[ a21  a22 ]

det(A) = (a11 * a22) - (a12 * a21)
```
```
方法一：对角线法则
[ a11  a12  a13 ]
[ a21  a22  a23 ]
[ a31  a32  a33 ]

(a11 * a22 * a33 + a12 * a23 * a31 + a13 * a21 * a32)-
(a13 * a22 * a31 + a11 * a23 * a32 + a12 * a21 * a33)
方法二：代数余子式展开（按第一行展开）
计算第一行每个元素的代数余子式
将每个元素与其对应的代数余子式相乘，然后相加
```
### 矩阵是否可逆
- 行列式不为零  矩阵一定可逆  这是充分必要条件


### 特征值和特征向量
- 征向量是矩阵变换中方向保持不变的特殊向量。
- 特征值是这些特殊向量在变换中被拉伸或缩小的比例。
```
Av=λv
λ 就被称为矩阵 A 的一个 特征值 (eigenvalue)。
v 就被称为矩阵 A 对应于特征值 λ 的一个 特征向量 (eigenvector)。
```
- 当矩阵 A 作用在特征向量 v 上时，其结果仍然是 v 的一个标量倍数 λ。也就是说，矩阵 A 对特征向量 v 的作用仅仅是将其长度缩放（或反向缩放，如果 λ 是负数），而不改变其方向。特征向量代表了矩阵变换的“不变方向”或者“主要方向”。特征值则代表了在这个不变方向上的缩放比例。



## 面试题
### 1.什么是矩阵的秩
- 线性无关的行向量数： 矩阵 A 的秩是构成线性无关集合的最大行向量数。这也被称为行秩 (row rank)。
- 也是线性无关的最大列向量数目
- 矩阵的秩就是矩阵中非零子式的最高阶数。（这里涉及到子式的概念  行列式的计算 什么是阶数）

### 2.什么是线性相关和线性无关？
- 如果存在不全为零的系数，使得向量集合果中的某些向量的线性组合等于零向量，那么这些向量就被称为线性相关的。
换句话说，如有向量v₁、v₂、v₃、...、vₙ，并且存在不全为零的标量c₁、c₂、c₃、...、cₙ，使得c₁v₁+ c₂v₂+ c₃v₃+ ... + cₙvₙ= 0，则这些向量就是线性相关的。
-  如果向量集合中的向量无法通过任何非平凡的线性组合（即非所有系数都为零）得到零向量，那么这些向量就是线性无关的。换句话说，如果 c₁v₁ + c₂v₂ + c₃v₃ + ... + cₙvₙ = 0 的唯一解是 c₁=c₂=...=cₙ=0，则这些向量就是线性无关的。

### 3.一个矩阵线性无关的等价定义有什么
行列式不为0，矩阵可逆，矩阵满秩，特征值没有 0（特征值）





### 4. 特征值和特征向量是什么 有什么应用

- 给定一个n×n的方阵A，若非零向量x满足Ax = λx，那么λ称为A的特征值。非零向量x称为A的征向量。特征向量x在经过矩阵 A 的线性变换后，只会改变长度但不会改变方向，而特征值则表示该变换的缩放比例。
- |A-λI|=0从而求得所有λ。将λi带回(A-λiI)x=0那么可求得方程组的基础解系，特征值为λi的特征向量就是基础解系的线性组合。
- **所有特征值的积是该矩阵的行列式（行列式的本质是特征值的乘积），所有特征值的和是该矩阵的迹。**
- 应用：       
    - 特征空间变换：特征向量可以用于将矩阵对角化，从而简化线性变换的描述。这在计算中能够提高效率。
    - 前馈神经网络 (Feed-Forward Network, FFN) FFN 独立地对每个标记的表示应用非线性变换。内部的升维允许学习更具表达性的函数，而随后的降维将这些学习到的特征集成回 Transformer 的信息流中。
    - 嵌入层: 将低维标记映射到更高维度的空间以捕获语义含义。
    - 自注意力: 可能涉及内部降维以提高计算效率和集中注意力，然后通过多头拼接进行升维，最后投影回原始维度。
    - 前馈神经网络: 使用临时的升维来学习复杂的非线性关系，然后再投影回原始维度。
    - 图像处理：特征值和特征向量可以用于图像压缩、降噪和特征提取等领域。例如，主成分分析（PCA）方法就利用了特征向量来提取图像中的关键特征。
    - 数据分析：特征值可以用于降维和数据拟合。例如，在主成分分析中，我们可以通过保留最大的特征值对应的特征向量进行数据降维，从而捕捉数据的主要变化趋势。

### 5.特征值为0表示什么？
 所有特征值的积是该矩阵的行列式，特征值为0说明行列式为0，一定不可逆，

# 概率论

## 知识

### 条件概率
- 在事件 B 发生的条件下，事件 A 发生的概率记为 P(A|B)，读作 “A 在 B 条件下发生的概率”。
- 条件概率的计算公式如下： P(A|B) = P(AB) / P(B)
- P(AB)表示事件A和事件B同时发生的概率。


### 全概率公式和贝叶斯公式
-  如果有一些互斥事件A1,A2,……,An，它们的并集是全集，则任何事件B发生的概率可以拆分为每一个Ai∩B的概率和。
```
       P(B)=P(A1)*P(B|A1)+P(A2)*P(B|A2)+...+P(An)*P(B|An)
```

- 机器学习中的贝叶斯公式
```
P(A|B) = (P(B|A) * P(A)) / P(B)
```
P(A|B) 是后验概率，P(B|A) 是似然度，P(A) 表示事件 A 的先验概率，P(B) 表示事件 B 的先验概率。
例如 P(患支气管炎|咳嗽)=P(有咳嗽|支气管炎)*P(支气管炎)/P(咳嗽)
P(支气管炎有咳嗽症状)是似然度，容易求得。P(支气管炎)和P(咳嗽)是先验概率。这样帮助医生根据症状预测患者患某种病的概率。
- 机器学习中贝叶斯分类器：根据已有的训练样本和特征信息，利用贝叶斯公式计算不同类别的后验概率，从而进行分类任务。
