---
layout:     post
title:      线性代数概率论复习
subtitle:   线性代数概率论复习
date:       2025-05-08
author:     Junvate
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 保研复习
---
# 高等数学


### 泰勒展开式
- 核心思想是用多项式无限逼近函数

泰勒公式的初衷是用多项式函数来近似表示函数在某点周围的情况。
泰勒公式可用于将一个函数在某个点附近展开成无穷级数的形式。
泰勒公式的一般形式如下：
f(x) = f(a) + f'(a)(x - a)/1! + f''(a)(x - a)²/2! + f'''(a)(x - a)³/3! + ...
f(x) 是要近似的函数，a 是展开点。

##  解释一下拉格朗日中值定理。★★
如果一个函数在闭区间上连续，在开区间内可导，则至少存在一个点，该点的导数等于函数在区间端点的斜率。


### 三个中值定理的区别、联系和应用
罗尔中值定理适用于闭区间内连续的函数。当函数在闭区间的端点上取相同的值时，罗尔中值定理保证函数在开区间内至少有一个导数为零的点。

拉格朗日中值定理适用于闭区间内连续且可导的函数。它是罗尔中值定理的推广，保证函数在开区间内至少有一个导数等于平均变化率的点。拉格朗日中值定理应用：在某个时间点，质点的瞬时速度等于它在某个时间段内的平均速度。


柯西中值定理适用于两个函数在闭区间内连续且可导。它是拉格朗日中值定理的推广，表示两个函数在开区间内的平均变化率等于它们在开区间内某个点的瞬时变化率的比值。

1. 罗尔中值定理 (Rolle's Theorem)

* 定理叙述：
    如果函数 f(x) 满足以下条件：
    1.  在闭区间 [a, b] 上连续；
    2.  在开区间 (a, b) 内可导；
    3.  在区间端点处的函数值相等，即 f(a) = f(b)。
    那么，在开区间 (a, b) 内至少存在一点 xi (xi)，使得 f'(xi) = 0。


2. 拉格朗日中值定理 (Lagrange's Mean Value Theorem)

* 定理叙述：
    如果函数 f(x) 满足以下条件：
    1.  在闭区间 [a, b] 上连续；
    2.  在开区间 (a, b) 内可导。
    那么，在开区间 (a, b) 内至少存在一点 xi，使得：
    f'(xi) = (f(b) - f(a)) / (b - a)

* 几何意义：
    如果一条连续且光滑的曲线，连接其两个端点 (a, f(a)) 和 (b, f(b)) 的割线斜率为 (f(b) - f(a)) / (b - a)。拉格朗日中值定理表明，在这条曲线上至少有一点的切线平行于这条割线。

* 应用：
    1.  估算函数值的近似和误差： f(x) = f(x_0) + f'(xi)(x-x_0)。当 x 接近 x_0 时，可以用 f(x) approx f(x_0) + f'(x_0)(x-x_0) 进行线性近似，拉格朗日中值定理给出了误差的精确表达。
    2.  证明不等式： 通过构造合适的函数，利用导数的符号来控制函数值的变化。
    3.  判断函数的单调性： 如果在区间 (a,b) 内 f'(x) > 0，则 f(x) 在该区间单调递增；如果 f'(x) < 0，则单调递减；如果 f'(x) = 0，则为常数。这是拉格朗日中值定理的直接推论。
    4.  微分学的基本定理： 它是推导许多重要微积分结论（如泰勒公式的拉格朗日余项、洛必达法则的部分证明）的基础。
    5.  连接原函数与导函数： 建立了函数在两点值的差与区间内某点导数值的直接关系。


3. 柯西中值定理 (Cauchy's Mean Value Theorem / Generalized Mean Value Theorem)

* 定理叙述：
    如果两个函数 f(x) 和 g(x) 满足以下条件：
    1.  在闭区间 [a, b] 上连续；
    2.  在开区间 (a, b) 内可导；
    3.  对于任意 x in (a, b)，g'(x) != 0。（这个条件保证了 g(b) - g(a) != 0）
    那么，在开区间 (a, b) 内至少存在一点 xi，使得：
    (f'(xi)) / (g'(xi)) = (f(b) - f(a)) / (g(b) - g(a))


## 方向导数和梯度

- 方向导数是一个标量。方向导数可以理解为函数在某个点的某个方向上的变化速率。
- 梯度是一个向量。它包含了函数在每个方向上变化最快的信息。对于一个多变量函数 f(x, y, z)，其梯度定义为：
∇f = (∂f/∂x, ∂f/∂y, ∂f/∂z)
梯度的方向是函数在某一点上变化最快的方向，而梯度的模长表示了函数在该点上的变化速率（或最大方向导数）。
梯度的几何意义：
函数变化增加最快的地方。沿着梯度向量的方向，更容易找到函数的最大值。反过来说，沿着梯度向量相反的方向，更容易找到函数的最小值。
梯度的应用：
最速下降法：梯度在优化问题中发挥重要作用。它利用梯度的负方向来搜索函数的最小值。根据最速下降法，沿着梯度的负方向进行迭代更新可以逐步接近函数的最小值。

方向导数和梯度的关系：
如果我们知道了函数在某一点的梯度向量，以及一个表示方向的单位向量，就可以计算出函数在这个方向上的方向导数。      

# 线性代数
## 复习



### 子式

对于一个 m×n 的矩阵 A，一个 k 阶子式是通过以下步骤得到的：
选择 k 行（1≤k≤m）。
选择 k 列（1≤k≤n）。
由这 k 行和 k 列交叉位置上的元素组成一个 k×k 的方阵。
这个 k×k 方阵的**行列式**就称为 A 的一个 k 阶子式。


### 满秩
对于一个 m×n 的矩阵 A，其秩 rank(A) 总是满足：
```
0≤rank(A)≤min(m,n)
rank(A)=m 行满秩 (row full rank)。这意味着矩阵的所有行向量都是线性无关的
rank(A)=n  列满秩 (column full rank)。这意味着矩阵的所有列向量都是线性无关的
对于方阵 (m=n)： 矩阵的秩等于其维度，即 rank(A)=n (或 m)。在这种情况下，我们通常直接称该矩阵为满秩
```

### 线性相关
- 对于一个方阵来说，行列式为 0 是其行向量（或列向量）线性相关的充分必要条件。
- 如果一个矩阵包含一个 k 阶的非零子式，那么对应的 k 行和 k 列是线性无关的 
- 如果这个行列式不为零，这意味着这个 k×k 子矩阵是可逆的。
- 如果矩阵的秩是 r，即存在 r 个线性无关的行向量（或列向量），那么我们可以找到一个 r×r 的子矩阵，其行列式不为零。 


### 基和维数
a. a1,a2,...,ar线性无关;
b. V中向量均可由 a1,a2,..., ar 线性表示
则称 a1,a2,...,ar 为V 的一个基。
基中所含向量个数 r 称为向量空间的维数

### 行列式计算
```
[ a11  a12 ]
[ a21  a22 ]

det(A) = (a11 * a22) - (a12 * a21)
```
```
方法一：对角线法则
[ a11  a12  a13 ]
[ a21  a22  a23 ]
[ a31  a32  a33 ]

(a11 * a22 * a33 + a12 * a23 * a31 + a13 * a21 * a32)-
(a13 * a22 * a31 + a11 * a23 * a32 + a12 * a21 * a33)
方法二：代数余子式展开（按第一行展开）
计算第一行每个元素的代数余子式
将每个元素与其对应的代数余子式相乘，然后相加
```
### 矩阵是否可逆
- 行列式不为零  矩阵一定可逆  这是充分必要条件


### 特征值和特征向量
- 特征向量是矩阵变换中方向保持不变的特殊向量。
- 特征值是这些特殊向量在变换中被拉伸或缩小的比例。
```
Av=λv
λ 就被称为矩阵 A 的一个 特征值 (eigenvalue)。
v 就被称为矩阵 A 对应于特征值 λ 的一个 特征向量 (eigenvector)。
```
- 当矩阵 A 作用在特征向量 v 上时，其结果仍然是 v 的一个标量倍数 λ。也就是说，矩阵 A 对特征向量 v 的作用仅仅是将其长度缩放（或反向缩放，如果 λ 是负数），而不改变其方向。特征向量代表了矩阵变换的“不变方向”或者“主要方向”。特征值则代表了在这个不变方向上的缩放比例。



## 面试题
### 1.什么是矩阵的秩
- 线性无关的行向量数： 矩阵 A 的秩是构成线性无关集合的最大行向量数。这也被称为行秩 (row rank)。
- 也是线性无关的最大列向量数目
- 矩阵的秩就是矩阵中非零子式的最高阶数。（这里涉及到子式的概念  行列式的计算 什么是阶数）

### 2.什么是线性相关和线性无关？
- 如果存在不全为零的系数，使得向量集合果中的某些向量的线性组合等于零向量，那么这些向量就被称为线性相关的。
换句话说，如有向量v₁、v₂、v₃、...、vₙ，并且存在不全为零的标量c₁、c₂、c₃、...、cₙ，使得c₁v₁+ c₂v₂+ c₃v₃+ ... + cₙvₙ= 0，则这些向量就是线性相关的。
-  如果向量集合中的向量无法通过任何非平凡的线性组合（即非所有系数都为零）得到零向量，那么这些向量就是线性无关的。换句话说，如果 c₁v₁ + c₂v₂ + c₃v₃ + ... + cₙvₙ = 0 的唯一解是 c₁=c₂=...=cₙ=0，则这些向量就是线性无关的。

### 3.一个矩阵线性无关的等价定义有什么
行列式不为0，矩阵可逆，矩阵满秩，特征值没有 0（特征值）





### 4. 特征值和特征向量是什么 有什么应用

- 给定一个n×n的方阵A，若非零向量x满足Ax = λx，那么λ称为A的特征值。非零向量x称为A的征向量。特征向量x在经过矩阵 A 的线性变换后，只会改变长度但不会改变方向，而特征值则表示该变换的缩放比例。
- |A-λI|=0从而求得所有λ。将λi带回(A-λiI)x=0那么可求得方程组的基础解系，特征值为λi的特征向量就是基础解系的线性组合。
- **所有特征值的积是该矩阵的行列式（行列式的本质是特征值的乘积），所有特征值的和是该矩阵的迹。**
- 应用：       
    - 特征空间变换：特征向量可以用于将矩阵对角化，从而简化线性变换的描述。这在计算中能够提高效率。
    - 前馈神经网络 (Feed-Forward Network, FFN) FFN 独立地对每个标记的表示应用非线性变换。内部的升维允许学习更具表达性的函数，而随后的降维将这些学习到的特征集成回 Transformer 的信息流中。
    - 嵌入层: 将低维标记映射到更高维度的空间以捕获语义含义。
    - 自注意力: 可能涉及内部降维以提高计算效率和集中注意力，然后通过多头拼接进行升维，最后投影回原始维度。
    - 前馈神经网络: 使用临时的升维来学习复杂的非线性关系，然后再投影回原始维度。
    - 图像处理：特征值和特征向量可以用于图像压缩、降噪和特征提取等领域。例如，主成分分析（PCA）方法就利用了特征向量来提取图像中的关键特征。
    - 数据分析：特征值可以用于降维和数据拟合。例如，在主成分分析中，我们可以通过保留最大的特征值对应的特征向量进行数据降维，从而捕捉数据的主要变化趋势。

### 5.特征值为0表示什么？
 所有特征值的积是该矩阵的行列式，特征值为0说明行列式为0，一定不可逆，

# 概率论

## 知识

### 条件概率
- 在事件 B 发生的条件下，事件 A 发生的概率记为 P(A|B)，读作 “A 在 B 条件下发生的概率”。
- 条件概率的计算公式如下： P(A|B) = P(AB) / P(B)
- P(AB)表示事件A和事件B同时发生的概率。


### 全概率公式和贝叶斯公式
-  如果有一些互斥事件A1,A2,……,An，它们的并集是全集，则任何事件B发生的概率可以拆分为每一个Ai∩B的概率和。
```
       P(B)=P(A1)*P(B|A1)+P(A2)*P(B|A2)+...+P(An)*P(B|An)
```

- 机器学习中的贝叶斯公式
```
P(A|B) = (P(B|A) * P(A)) / P(B)
```
P(A|B) 是后验概率，P(B|A) 是似然度，P(A) 表示事件 A 的先验概率，P(B) 表示事件 B 的先验概率。
例如 P(患支气管炎|咳嗽)=P(有咳嗽|支气管炎)*P(支气管炎)/P(咳嗽)
P(支气管炎有咳嗽症状)是似然度，容易求得。P(支气管炎)和P(咳嗽)是先验概率。这样帮助医生根据症状预测患者患某种病的概率。
- 机器学习中贝叶斯分类器：根据已有的训练样本和特征信息，利用贝叶斯公式计算不同类别的后验概率，从而进行分类任务。
